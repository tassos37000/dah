{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "967ce15b-41d6-4bad-bf37-8d74a10ffbd3",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac0ca65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModelForSequenceClassification\n",
    "from datasets import load_from_disk\n",
    "\n",
    "from config import DEVICE\n",
    "from generate_answers import generate_answers\n",
    "from my_utils.data import sample_ds, load_ds\n",
    "from my_utils.metrics import calculate_auroc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a224c67",
   "metadata": {},
   "source": [
    "# Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddee37fc-ef8b-44a9-8fb5-a4d8b8cd7b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcbc1d296d8e473ea000d3be0e1cc12c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5229745664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6651206656\n",
      "9739567616\n"
     ]
    }
   ],
   "source": [
    "print(DEVICE)\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "\n",
    "# LLM\n",
    "Gemma_model = AutoModelForCausalLM.from_pretrained(\"google/gemma-2-2b-it\", device_map=\"auto\", torch_dtype=torch.bfloat16)\n",
    "Gemma_tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2-2b-it\")\n",
    "\n",
    "# Entailment Transformer\n",
    "Roberta_model = AutoModelForSequenceClassification.from_pretrained(\"roberta-large-mnli\").to(DEVICE)\n",
    "Roberta_tokenizer = AutoTokenizer.from_pretrained(\"roberta-large-mnli\")\n",
    "print(torch.cuda.memory_allocated())\n",
    "\n",
    "# Entailment LLM\n",
    "Qwen_model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2.5-1.5B-Instruct\", torch_dtype=\"auto\", device_map=\"auto\").to(DEVICE)\n",
    "Qwen_tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-1.5B-Instruct\")\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec44b227",
   "metadata": {},
   "source": [
    "# Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37d6243e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  trivia_qa\n",
      "Dataset({\n",
      "    features: ['id', 'question', 'context', 'answers'],\n",
      "    num_rows: 4\n",
      "}) \n",
      "\n",
      "Dataset:  squad\n",
      "Dataset({\n",
      "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
      "    num_rows: 4\n",
      "}) \n",
      "\n",
      "Dataset:  svamp\n",
      "Dataset({\n",
      "    features: ['ID', 'Body', 'Question', 'Equation', 'Answer', 'Type', 'question_concat', 'question', 'context', 'type', 'equation', 'id', 'answers'],\n",
      "    num_rows: 4\n",
      "}) \n",
      "\n",
      "Dataset:  nq\n",
      "Dataset({\n",
      "    features: ['question', 'answer', 'answers', 'context', 'id'],\n",
      "    num_rows: 4\n",
      "}) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_samples = 4\n",
    "triviaqa_train, triviaqa_val = load_ds(\"trivia_qa\", seed)\n",
    "squad_train, squad_val = load_ds(\"squad\", seed)\n",
    "svamp_train, svamp_val = load_ds(\"svamp\", seed)\n",
    "nq_train, nq_val = load_ds(\"nq\", seed)\n",
    "\n",
    "\n",
    "triviaqa_sample = sample_ds(triviaqa_val, n_samples, seed, \"trivia_qa\")\n",
    "squad_sample = sample_ds(squad_val, n_samples, seed, \"squad\")\n",
    "svamp_sample = sample_ds(svamp_val, n_samples, seed, \"svamp\")\n",
    "nq_sample = sample_ds(nq_val, n_samples, seed, \"nq\")\n",
    "\n",
    "datasets = [triviaqa_sample, squad_sample, svamp_sample, nq_sample]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f170ee9c",
   "metadata": {},
   "source": [
    "# Generate answers and calculate Semantic Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226783ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating responses for trivia_qa dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]c:\\Users\\tasso\\anaconda3\\envs\\mscs\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:370: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "100%|██████████| 4/4 [02:19<00:00, 34.82s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc72661191a647b4865dc1f8d577ec1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/4 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afc02fc129b94df19a5812e8051b5720",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/4 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating responses for squad dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [03:08<00:00, 47.02s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86059b3a10b54bbbaba27bf3af417802",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/4 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3a22a3cb8c64184b64052ecd5a24fc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/4 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating responses for svamp dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [01:26<00:00, 21.66s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "103c7fccc46041c9984fd201ab4d9d5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/4 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e9b6ff50275461e952271c728f8b12b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/4 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating responses for nq dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [02:21<00:00, 35.50s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c4ca828b8cb41298be1e8f9903e6585",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/4 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34d1ee0460ec46409754a038df3efef4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/4 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_transformer_path = \"data/transformer/\"\n",
    "data_llm_path = \"data/llm/\"\n",
    "generate_answers(datasets, data_transformer_path, data_llm_path, Gemma_model, Gemma_tokenizer, Roberta_model, Roberta_tokenizer, Qwen_model, Qwen_tokenizer)\n",
    "\n",
    "del triviaqa_train, triviaqa_val, squad_train, squad_val, svamp_train, svamp_val, nq_train, nq_val \n",
    "del triviaqa_sample, squad_sample, svamp_sample, nq_sample, datasets\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1443104e",
   "metadata": {},
   "source": [
    "# Load Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1437d735",
   "metadata": {},
   "outputs": [],
   "source": [
    "triviaqa_sample = load_from_disk(data_transformer_path + \"trivia_qa\")\n",
    "squad_sample = load_from_disk(data_transformer_path + \"squad\")\n",
    "svamp_sample = load_from_disk(data_transformer_path + \"svamp\")\n",
    "nq_sample = load_from_disk(data_transformer_path + \"nq\")\n",
    "datasets_transformers = [triviaqa_sample, squad_sample, svamp_sample, nq_sample]\n",
    "\n",
    "triviaqa_sample = load_from_disk(data_llm_path + \"trivia_qa\")\n",
    "squad_sample = load_from_disk(data_transformer_path + \"squad\")\n",
    "svamp_sample = load_from_disk(data_llm_path + \"svamp\")\n",
    "nq_sample = load_from_disk(data_llm_path + \"nq\")\n",
    "datasets_llm = [triviaqa_sample, squad_sample, svamp_sample, nq_sample]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e709cb64",
   "metadata": {},
   "source": [
    "# Calculate Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17d92b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC scores for Transformer\n",
      "AUROC score for trivia_qa dataset: 0.0\n",
      "AUROC score for squad dataset: 0.0\n",
      "AUROC score for svamp dataset: 0.6666666666666667\n",
      "AUROC score for nq dataset: 1.0\n",
      "\n",
      "AUROC scores for LLM\n",
      "AUROC score for trivia_qa dataset: 0.33333333333333337\n",
      "AUROC score for squad dataset: 0.0\n",
      "AUROC score for svamp dataset: 0.6666666666666667\n",
      "AUROC score for nq dataset: 0.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.33333333333333337, 0.0, 0.6666666666666667, 0.5]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"AUROC scores for Transformer\")\n",
    "calculate_auroc(datasets_transformers)\n",
    "\n",
    "print(\"\\nAUROC scores for LLM\")\n",
    "calculate_auroc(datasets_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434a3338",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "mscs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
